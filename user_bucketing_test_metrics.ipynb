{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "associate-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.download_from_GCP import download_table_to_local_as_one_file\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import ndcg_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import pathlib\n",
    "import xlearn as xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGS = [\n",
    "#     \"Punjabi\",\n",
    "    \"Hindi\",\n",
    "    # \"Tamil\",\n",
    "#     \"Telugu\",\n",
    "#     \"Kannada\",\n",
    "#     \"Odia\",\n",
    "#     \"Bengali\",\n",
    "#     \"Marathi\",\n",
    "#     \"Malayalam\",\n",
    "#     \"Gujarati\",\n",
    "]\n",
    "# DAYS_OF_DATA_CONSIDERED = 7\n",
    "rating_def_dict = {\n",
    "#         \"vplay\": \"is_vp_succ\",\n",
    "# #         \"share\": \"is_share\",\n",
    "# #         \"fav\": \"is_fav\",\n",
    "        \"like\": \"is_like\",\n",
    "        \"vplay2\": \"is_vp_succ2\",\n",
    "#         \"vplay_skip\": \"is_vp_skip\",\n",
    "#     \"vclick\": \"is_vp_click\"\n",
    "}\n",
    "\n",
    "# table_path = \"maximal-furnace-783.rohitrr.test_temp_q1_table_Malayalam_is_vp_succ2\"\n",
    "# local_save_path = \"./train_test_data_models/Malayalam/is_vp_succ2\"\n",
    "# out_file_name = \"test_q1.csv\"\n",
    "min_pos_labels = 1\n",
    "min_total_user_events = 1\n",
    "num_users_to_consider = 20000\n",
    "RANDOM_SEED = 9745\n",
    "TEST_DATA_FILE_NAME = \"test\"\n",
    "USER_CONTEXT = \"location\"\n",
    "DTYPE=\"video\"\n",
    "results_path = f\"results/user_bucketing_metrics_1.csv\"\n",
    "new_results_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marine-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appointed-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scores(test_file_path, test_model_path, predicted_output_folder_path, \n",
    "                   rating_def, lang, predicted_output_file_name = \"predicted_output.txt\"):\n",
    "    pathlib.Path(predicted_output_folder_path).mkdir(parents = True, exist_ok = True)\n",
    "    predicted_output_file_path = os.path.join(predicted_output_folder_path,\n",
    "                                             predicted_output_file_name)\n",
    "    res_out_path = os.path.join(predicted_output_folder_path, \"results.csv\")\n",
    "    \n",
    "    print(f\"Predicting labels for {rating_def}-{lang} .... \")\n",
    "    ffm_model = xl.create_ffm() \n",
    "    ffm_model.setTest(test_file_path)\n",
    "    ffm_model.setSigmoid()\n",
    "    ffm_model.predict(test_model_path, predicted_output_file_path)\n",
    "    print(f\"Predicted labels stored in {predicted_output_file_path}\")\n",
    "\n",
    "def get_test_df(test_file_path, predicted_results_path):\n",
    "    print(f\"Reading - {predicted_results_path}\")\n",
    "    with open(predicted_results_path) as f:\n",
    "        lines = f.readlines()\n",
    "        predicted_scores = [float(score.replace('\\n','')) for score in lines]\n",
    "    user_mappings = []\n",
    "    scores = []\n",
    "    \n",
    "    print(f\"Reading - {test_file_path}\")\n",
    "    with open(test_file_path) as f:\n",
    "        for l in f:\n",
    "            user_mappings.append(int(l.split(':')[1]))\n",
    "            scores.append(int(l[0]))\n",
    "    dataframe_dict = {\n",
    "        \"user_mapping\": user_mappings,\n",
    "        \"score\": scores,\n",
    "        \"predicted_score\": predicted_scores\n",
    "    }\n",
    "    df = pd.DataFrame(dataframe_dict)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def calculate_user_level_metric_scores(true_vals, predicted_vals):\n",
    "        user_auc_score = roc_auc_score(true_vals, predicted_vals)\n",
    "        user_at_5_ndcg_score = ndcg_score(true_vals[np.newaxis, :], predicted_vals[np.newaxis, :],\n",
    "                                         k = 5)\n",
    "        user_at_10_ndcg_score = ndcg_score(true_vals[np.newaxis, :], predicted_vals[np.newaxis, :],\n",
    "                                         k = 10)\n",
    "        relevant_recommendations = np.where(true_vals == 1)[0]\n",
    "        ordered_recommendations = np.argsort(-predicted_vals)\n",
    "        user_mapk_at_5_score = apk(relevant_recommendations, ordered_recommendations, k=5)\n",
    "        user_mapk_at_10_score = apk(relevant_recommendations, ordered_recommendations, k=10)\n",
    "        return [user_auc_score, user_at_5_ndcg_score, user_at_10_ndcg_score,\n",
    "                user_mapk_at_5_score, user_mapk_at_10_score]\n",
    "    #     print(\"appended\")\n",
    "\n",
    "def get_auc_score(test_df):\n",
    "    scores = test_df[\"score\"].values\n",
    "    predicted_scores = test_df[\"predicted_score\"].values\n",
    "    print(f\"Calculating overall AUC scores\")\n",
    "    auc_overall = roc_auc_score(scores, predicted_scores)\n",
    "    print(f\"Overall AUC scores computed\")\n",
    "    return auc_overall\n",
    "\n",
    "def filter_user_level_indices(df):\n",
    "    print(f\"Separating data into groups .....\")\n",
    "    agg_df = df[['user_mapping', 'score']].groupby(['user_mapping']).agg(['sum', 'count'])\n",
    "    agg_df = agg_df[(agg_df[\"score\"][\"sum\"] >= min_pos_labels) \\\n",
    "                     & (agg_df[\"score\"][\"count\"] >= min_total_user_events) \\\n",
    "                   & (agg_df[\"score\"][\"sum\"] != agg_df[\"score\"][\"count\"])]\n",
    "    selected_user_mappings = agg_df.sample(n = min(num_users_to_consider, agg_df.shape[0]), \n",
    "                                     replace=False, random_state=RANDOM_SEED).index.values\n",
    "    user_level_inds = df.index[df.user_mapping.isin(selected_user_mappings)]\n",
    "    print(f\"No. of users in user level metrics computations - {len(selected_user_mappings)}\")\n",
    "    print(\"Filtered data\")\n",
    "    return user_level_inds\n",
    "    \n",
    "def get_user_level_results(df):\n",
    "    df = df.sort_values(\"user_mapping\")\n",
    "    all_user_mappings = df.user_mapping.values\n",
    "    scores = df.score.values\n",
    "    predicted_scores = df.predicted_score.values\n",
    "    ukeys, index = np.unique(all_user_mappings, True)\n",
    "    user_level_true_vals = np.split(scores, index[1:])\n",
    "    user_level_predicted_vals = np.split(predicted_scores, index[1:])\n",
    "    input_vals = list(zip(user_level_true_vals, user_level_predicted_vals))\n",
    "    \n",
    "    print(f\"Computing different scores ....\")\n",
    "    with Pool(processes = 48) as sub_pool:\n",
    "        res = sub_pool.starmap(calculate_user_level_metric_scores, input_vals)       \n",
    "    means = np.array(res).mean(axis = 0)\n",
    "    \n",
    "    results_dict = {\n",
    "        \"AUC score - User Level\": means[0],\n",
    "        \"NDCG@5 Score - User Level\": means[1],\n",
    "        \"NDCG@10 Score - User Level\": means[2],\n",
    "        \"MAPK@5 score - User Level\": means[3],\n",
    "        \"MAPK@10 score - User Level\": means[4]\n",
    "        }\n",
    "    print(\"Completed computing results - {}\".format(results_dict))\n",
    "    return results_dict\n",
    "\n",
    "# def get_model_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acquired-american",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading - ./train_test_data_models/location/video/Hindi/is_like/predicted_results/predicted_scores.txt\n",
      "Reading - ./train_test_data_models/location/video/Hindi/is_like/test.txt\n",
      "Getting and transforming user buckets ....\n",
      "Computing scores for each bucket - location/video/Hindi/is_like\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6473710959751081, 'NDCG@5 Score - User Level': 0.4812755679184771, 'NDCG@10 Score - User Level': 0.5353513155103987, 'MAPK@5 score - User Level': 0.3942697499999991, 'MAPK@10 score - User Level': 0.4191203939200643}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6692418426521624, 'NDCG@5 Score - User Level': 0.42132655280356773, 'NDCG@10 Score - User Level': 0.47571815840247517, 'MAPK@5 score - User Level': 0.34108844444444647, 'MAPK@10 score - User Level': 0.3638435421863184}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6703174516539006, 'NDCG@5 Score - User Level': 0.3921591729638972, 'NDCG@10 Score - User Level': 0.44167170393082444, 'MAPK@5 score - User Level': 0.31540725000000214, 'MAPK@10 score - User Level': 0.3339570586104795}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6719324058189231, 'NDCG@5 Score - User Level': 0.3652032315525443, 'NDCG@10 Score - User Level': 0.4135027724306479, 'MAPK@5 score - User Level': 0.29109787500000334, 'MAPK@10 score - User Level': 0.3083074189027478}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6710138845006499, 'NDCG@5 Score - User Level': 0.34626192552126606, 'NDCG@10 Score - User Level': 0.3896183371257823, 'MAPK@5 score - User Level': 0.2750326250000023, 'MAPK@10 score - User Level': 0.28846364765999144}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6723816784268463, 'NDCG@5 Score - User Level': 0.3208888431178859, 'NDCG@10 Score - User Level': 0.3608004615500288, 'MAPK@5 score - User Level': 0.25149813888889117, 'MAPK@10 score - User Level': 0.26291750911753753}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.669772840830002, 'NDCG@5 Score - User Level': 0.29464151446718506, 'NDCG@10 Score - User Level': 0.3310639880104032, 'MAPK@5 score - User Level': 0.22939270833333644, 'MAPK@10 score - User Level': 0.23755827485670292}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6668408686613265, 'NDCG@5 Score - User Level': 0.2717289329032148, 'NDCG@10 Score - User Level': 0.30135866123707966, 'MAPK@5 score - User Level': 0.20945701388889007, 'MAPK@10 score - User Level': 0.21347818722442866}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6647919614352139, 'NDCG@5 Score - User Level': 0.24175015449526027, 'NDCG@10 Score - User Level': 0.2667071978536246, 'MAPK@5 score - User Level': 0.18354902777777862, 'MAPK@10 score - User Level': 0.18408705070546896}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.6523582378866306, 'NDCG@5 Score - User Level': 0.1863544649648647, 'NDCG@10 Score - User Level': 0.20285889889213335, 'MAPK@5 score - User Level': 0.13650055555555488, 'MAPK@10 score - User Level': 0.13354853006109926}\n",
      "Reading - ./train_test_data_models/location/video/Hindi/is_vp_succ2/predicted_results/predicted_scores.txt\n",
      "Reading - ./train_test_data_models/location/video/Hindi/is_vp_succ2/test.txt\n",
      "Getting and transforming user buckets ....\n",
      "Computing scores for each bucket - location/video/Hindi/is_vp_succ2\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7323450733374639, 'NDCG@5 Score - User Level': 0.6356979843684256, 'NDCG@10 Score - User Level': 0.6765668848422242, 'MAPK@5 score - User Level': 0.5405978194444587, 'MAPK@10 score - User Level': 0.5570201637613394}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7381005896449404, 'NDCG@5 Score - User Level': 0.6137697296797519, 'NDCG@10 Score - User Level': 0.6541785839137481, 'MAPK@5 score - User Level': 0.5175050416666747, 'MAPK@10 score - User Level': 0.5315343547335647}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7376892096263468, 'NDCG@5 Score - User Level': 0.5989098172588475, 'NDCG@10 Score - User Level': 0.641474474383511, 'MAPK@5 score - User Level': 0.5019490000000109, 'MAPK@10 score - User Level': 0.5163178646463268}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7425008713822924, 'NDCG@5 Score - User Level': 0.5898626732320846, 'NDCG@10 Score - User Level': 0.6299180473667276, 'MAPK@5 score - User Level': 0.49146188888889936, 'MAPK@10 score - User Level': 0.5031241018282308}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7465944797646499, 'NDCG@5 Score - User Level': 0.5854992749875472, 'NDCG@10 Score - User Level': 0.6248576575827826, 'MAPK@5 score - User Level': 0.48697488888889884, 'MAPK@10 score - User Level': 0.4965980717592597}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7482572393855108, 'NDCG@5 Score - User Level': 0.5762881285456523, 'NDCG@10 Score - User Level': 0.6124110967726359, 'MAPK@5 score - User Level': 0.4755518888889029, 'MAPK@10 score - User Level': 0.48113966259605595}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.752314044611484, 'NDCG@5 Score - User Level': 0.570729461466649, 'NDCG@10 Score - User Level': 0.6013265276650803, 'MAPK@5 score - User Level': 0.46911450000001526, 'MAPK@10 score - User Level': 0.467779703310025}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7577506515462469, 'NDCG@5 Score - User Level': 0.5635095939564118, 'NDCG@10 Score - User Level': 0.5873327405834451, 'MAPK@5 score - User Level': 0.4599184583333472, 'MAPK@10 score - User Level': 0.45120303491905944}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7640726788496489, 'NDCG@5 Score - User Level': 0.5487219640044024, 'NDCG@10 Score - User Level': 0.562004693654099, 'MAPK@5 score - User Level': 0.4429858472222389, 'MAPK@10 score - User Level': 0.42174186968537325}\n",
      "Calculating overall AUC scores\n",
      "Overall AUC scores computed\n",
      "Separating data into groups .....\n",
      "No. of users in user level metrics computations - 20000\n",
      "Filtered data\n",
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7654722070496801, 'NDCG@5 Score - User Level': 0.523175435705283, 'NDCG@10 Score - User Level': 0.5202096038378131, 'MAPK@5 score - User Level': 0.4141348888889093, 'MAPK@10 score - User Level': 0.3758025714600664}\n",
      "[{'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 1, 'Num Bucket Samples': 4608011, 'AUC score': 0.775541339898969, 'AUC score - User Level': 0.6473710959751081, 'NDCG@5 Score - User Level': 0.4812755679184771, 'NDCG@10 Score - User Level': 0.5353513155103987, 'MAPK@5 score - User Level': 0.3942697499999991, 'MAPK@10 score - User Level': 0.4191203939200643}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 2, 'Num Bucket Samples': 9407093, 'AUC score': 0.8302580281949805, 'AUC score - User Level': 0.6692418426521624, 'NDCG@5 Score - User Level': 0.42132655280356773, 'NDCG@10 Score - User Level': 0.47571815840247517, 'MAPK@5 score - User Level': 0.34108844444444647, 'MAPK@10 score - User Level': 0.3638435421863184}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 3, 'Num Bucket Samples': 14011965, 'AUC score': 0.8577210085941421, 'AUC score - User Level': 0.6703174516539006, 'NDCG@5 Score - User Level': 0.3921591729638972, 'NDCG@10 Score - User Level': 0.44167170393082444, 'MAPK@5 score - User Level': 0.31540725000000214, 'MAPK@10 score - User Level': 0.3339570586104795}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 4, 'Num Bucket Samples': 20681123, 'AUC score': 0.8771862612327073, 'AUC score - User Level': 0.6719324058189231, 'NDCG@5 Score - User Level': 0.3652032315525443, 'NDCG@10 Score - User Level': 0.4135027724306479, 'MAPK@5 score - User Level': 0.29109787500000334, 'MAPK@10 score - User Level': 0.3083074189027478}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 5, 'Num Bucket Samples': 28202117, 'AUC score': 0.8911716648289734, 'AUC score - User Level': 0.6710138845006499, 'NDCG@5 Score - User Level': 0.34626192552126606, 'NDCG@10 Score - User Level': 0.3896183371257823, 'MAPK@5 score - User Level': 0.2750326250000023, 'MAPK@10 score - User Level': 0.28846364765999144}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 6, 'Num Bucket Samples': 38697044, 'AUC score': 0.9014640750967667, 'AUC score - User Level': 0.6723816784268463, 'NDCG@5 Score - User Level': 0.3208888431178859, 'NDCG@10 Score - User Level': 0.3608004615500288, 'MAPK@5 score - User Level': 0.25149813888889117, 'MAPK@10 score - User Level': 0.26291750911753753}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 7, 'Num Bucket Samples': 51680056, 'AUC score': 0.9096842197416302, 'AUC score - User Level': 0.669772840830002, 'NDCG@5 Score - User Level': 0.29464151446718506, 'NDCG@10 Score - User Level': 0.3310639880104032, 'MAPK@5 score - User Level': 0.22939270833333644, 'MAPK@10 score - User Level': 0.23755827485670292}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 8, 'Num Bucket Samples': 68212579, 'AUC score': 0.9167493586856929, 'AUC score - User Level': 0.6668408686613265, 'NDCG@5 Score - User Level': 0.2717289329032148, 'NDCG@10 Score - User Level': 0.30135866123707966, 'MAPK@5 score - User Level': 0.20945701388889007, 'MAPK@10 score - User Level': 0.21347818722442866}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 9, 'Num Bucket Samples': 102904577, 'AUC score': 0.9226981545727387, 'AUC score - User Level': 0.6647919614352139, 'NDCG@5 Score - User Level': 0.24175015449526027, 'NDCG@10 Score - User Level': 0.2667071978536246, 'MAPK@5 score - User Level': 0.18354902777777862, 'MAPK@10 score - User Level': 0.18408705070546896}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'like', 'Bucket': 10, 'Num Bucket Samples': 195296044, 'AUC score': 0.9298188996294999, 'AUC score - User Level': 0.6523582378866306, 'NDCG@5 Score - User Level': 0.1863544649648647, 'NDCG@10 Score - User Level': 0.20285889889213335, 'MAPK@5 score - User Level': 0.13650055555555488, 'MAPK@10 score - User Level': 0.13354853006109926}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 1, 'Num Bucket Samples': 6841216, 'AUC score': 0.7719714237666961, 'AUC score - User Level': 0.7323450733374639, 'NDCG@5 Score - User Level': 0.6356979843684256, 'NDCG@10 Score - User Level': 0.6765668848422242, 'MAPK@5 score - User Level': 0.5405978194444587, 'MAPK@10 score - User Level': 0.5570201637613394}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 2, 'Num Bucket Samples': 10872775, 'AUC score': 0.7794383221781179, 'AUC score - User Level': 0.7381005896449404, 'NDCG@5 Score - User Level': 0.6137697296797519, 'NDCG@10 Score - User Level': 0.6541785839137481, 'MAPK@5 score - User Level': 0.5175050416666747, 'MAPK@10 score - User Level': 0.5315343547335647}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 3, 'Num Bucket Samples': 14854385, 'AUC score': 0.7857290221352954, 'AUC score - User Level': 0.7376892096263468, 'NDCG@5 Score - User Level': 0.5989098172588475, 'NDCG@10 Score - User Level': 0.641474474383511, 'MAPK@5 score - User Level': 0.5019490000000109, 'MAPK@10 score - User Level': 0.5163178646463268}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 4, 'Num Bucket Samples': 21658196, 'AUC score': 0.7926097134147609, 'AUC score - User Level': 0.7425008713822924, 'NDCG@5 Score - User Level': 0.5898626732320846, 'NDCG@10 Score - User Level': 0.6299180473667276, 'MAPK@5 score - User Level': 0.49146188888889936, 'MAPK@10 score - User Level': 0.5031241018282308}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 5, 'Num Bucket Samples': 30871760, 'AUC score': 0.7986071503527508, 'AUC score - User Level': 0.7465944797646499, 'NDCG@5 Score - User Level': 0.5854992749875472, 'NDCG@10 Score - User Level': 0.6248576575827826, 'MAPK@5 score - User Level': 0.48697488888889884, 'MAPK@10 score - User Level': 0.4965980717592597}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 6, 'Num Bucket Samples': 42487280, 'AUC score': 0.8039640807685806, 'AUC score - User Level': 0.7482572393855108, 'NDCG@5 Score - User Level': 0.5762881285456523, 'NDCG@10 Score - User Level': 0.6124110967726359, 'MAPK@5 score - User Level': 0.4755518888889029, 'MAPK@10 score - User Level': 0.48113966259605595}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 7, 'Num Bucket Samples': 59817243, 'AUC score': 0.8079965595406452, 'AUC score - User Level': 0.752314044611484, 'NDCG@5 Score - User Level': 0.570729461466649, 'NDCG@10 Score - User Level': 0.6013265276650803, 'MAPK@5 score - User Level': 0.46911450000001526, 'MAPK@10 score - User Level': 0.467779703310025}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 8, 'Num Bucket Samples': 92092206, 'AUC score': 0.8117235087562629, 'AUC score - User Level': 0.7577506515462469, 'NDCG@5 Score - User Level': 0.5635095939564118, 'NDCG@10 Score - User Level': 0.5873327405834451, 'MAPK@5 score - User Level': 0.4599184583333472, 'MAPK@10 score - User Level': 0.45120303491905944}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 9, 'Num Bucket Samples': 143347384, 'AUC score': 0.8147959115613732, 'AUC score - User Level': 0.7640726788496489, 'NDCG@5 Score - User Level': 0.5487219640044024, 'NDCG@10 Score - User Level': 0.562004693654099, 'MAPK@5 score - User Level': 0.4429858472222389, 'MAPK@10 score - User Level': 0.42174186968537325}, {'User Context': 'location', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 10, 'Num Bucket Samples': 345662923, 'AUC score': 0.8182457371471396, 'AUC score - User Level': 0.7654722070496801, 'NDCG@5 Score - User Level': 0.523175435705283, 'NDCG@10 Score - User Level': 0.5202096038378131, 'MAPK@5 score - User Level': 0.4141348888889093, 'MAPK@10 score - User Level': 0.3758025714600664}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for lang in LANGS:\n",
    "    for rating_key, rating_def in rating_def_dict.items():\n",
    "        test_file_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}/{TEST_DATA_FILE_NAME}.txt\"\n",
    "        trained_model_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}/out/model.out\"\n",
    "        predicted_output_folder_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}/predicted_results\"\n",
    "        user_buckets_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}/user_buckets.csv\"\n",
    "        mapping_file_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}/user_post_ffm_mapping.csv\"\n",
    "        predicted_output_file_name = \"predicted_scores.txt\"\n",
    "        \n",
    "        predict_scores(test_file_path, trained_model_path, predicted_output_folder_path,\n",
    "                      lang, rating_def, predicted_output_file_name=predicted_output_file_name)\n",
    "        predicted_output_file_path = os.path.join(predicted_output_folder_path, \n",
    "                                                 predicted_output_file_name)\n",
    "        test_df = get_test_df(test_file_path, predicted_output_file_path)\n",
    "        print(\"Getting and transforming user buckets ....\")\n",
    "        user_buckets = pd.read_csv(user_buckets_path,\n",
    "                                delimiter=\"\\t\")\n",
    "        user_buckets[\"userId\"] = user_buckets.userId.map(lambda x: \"2_user_\"+str(x))\n",
    "        mapping_df = pd.read_csv(mapping_file_path,\n",
    "                        delimiter=\"\\t\", index_col=\"feature_name\")\n",
    "        user_buckets[\"user_mapping\"] = mapping_df.loc[list(user_buckets.userId.values)].mapping.values\n",
    "\n",
    "        print(f\"Computing scores for each bucket - {USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}\")\n",
    "        for i in range(10):\n",
    "            res = {\n",
    "                    \"User Context\": USER_CONTEXT,\n",
    "                    \"Content Type\": DTYPE,\n",
    "                    \"Language\": lang,\n",
    "                    \"Action Type\": rating_key\n",
    "                }\n",
    "            res[\"Bucket\"] = i+1\n",
    "            user_bucket_mappings = user_buckets[user_buckets.user_bucket==i+1].user_mapping.values\n",
    "            bucket_test_df = test_df[test_df.user_mapping.isin(user_bucket_mappings)]\n",
    "            res[\"Num Bucket Samples\"] = bucket_test_df.shape[0]\n",
    "            res[\"AUC score\"] = get_auc_score(bucket_test_df)\n",
    "            user_level_indices = filter_user_level_indices(bucket_test_df)\n",
    "            user_level_df = bucket_test_df.loc[user_level_indices]\n",
    "            res.update(get_user_level_results(user_level_df))\n",
    "\n",
    "            if(new_results_file):\n",
    "                pd.DataFrame(columns = list(res.keys())).to_csv(results_path, index=False)\n",
    "                new_results_file = False\n",
    "            pd.DataFrame([res]).to_csv(results_path, index=False, header=False, mode='a')\n",
    "            results.append(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-variance",
   "metadata": {},
   "source": [
    "### Scrap code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "threaded-bottom",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bucket_test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bad5a7484f99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbucket_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bucket_test_df' is not defined"
     ]
    }
   ],
   "source": [
    "bucket_test_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "blind-burlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607732, (6841216, 3), (769910170, 3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_level_indices), bucket_test_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "rural-shopper",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_level_df = bucket_test_df.loc[user_level_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aerial-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing different scores ....\n",
      "Completed computing results - {'AUC score - User Level': 0.7329352687842821, 'NDCG@5 Score - User Level': 0.6356111220019085, 'NDCG@10 Score - User Level': 0.6766040128600278, 'MAPK@5 score - User Level': 0.5406051805555684, 'MAPK@10 score - User Level': 0.5571550874275671}\n",
      "{'User Context': 'price', 'Content Type': 'video', 'Language': 'Hindi', 'Action Type': 'vplay2', 'Bucket': 1, 'AUC score': 0.7717333185050684, 'AUC score - User Level': 0.7329352687842821, 'NDCG@5 Score - User Level': 0.6356111220019085, 'NDCG@10 Score - User Level': 0.6766040128600278, 'MAPK@5 score - User Level': 0.5406051805555684, 'MAPK@10 score - User Level': 0.5571550874275671}\n"
     ]
    }
   ],
   "source": [
    "res.update(get_user_level_results(user_level_df))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "becoming-height",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_mapping</th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>769909377</th>\n",
       "      <td>19872422</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769909796</th>\n",
       "      <td>9833250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769909852</th>\n",
       "      <td>12746792</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769909980</th>\n",
       "      <td>15639665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769910149</th>\n",
       "      <td>8396586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_mapping  score  predicted_score\n",
       "769909377      19872422      1         0.380433\n",
       "769909796       9833250      0         0.330722\n",
       "769909852      12746792      0         0.030882\n",
       "769909980      15639665      0         0.254021\n",
       "769910149       8396586      0         0.126932"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_test_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "baking-monroe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_mapping</th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>14689468</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>10526039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>1465576</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>11590350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>13141315</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_mapping  score  predicted_score\n",
       "2067      14689468      0         0.298931\n",
       "2402      10526039      0         0.064852\n",
       "2983       1465576      0         0.078399\n",
       "4597      11590350      1         0.101524\n",
       "4745      13141315      0         0.695729"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_level_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "nasty-procurement",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769908636"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_level_indices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "general-diamond",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_mapping</th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239827</th>\n",
       "      <td>16662258</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281687</th>\n",
       "      <td>12484068</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351794</th>\n",
       "      <td>11990025</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_mapping  score  predicted_score\n",
       "239827      16662258      0         0.086504\n",
       "281687      12484068      0         0.229020\n",
       "351794      11990025      0         0.177217"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_level_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ambient-exercise",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for Malayalam-is_vp_skip\n",
      "Opening ./train_test_data_models/Malayalam/is_vp_skip/predicted_results/predicted_scores.txt and ./train_test_data_models/Malayalam/is_vp_skip/test.txt - reading input ............\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1a6c4851bd43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_results_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mpredicted_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0muser_mappings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1a6c4851bd43>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_results_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mpredicted_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0muser_mappings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lang in LANGS:\n",
    "    for rating_key, rating_def in rating_def_dict.items():\n",
    "        print(\"Getting results for {}-{}\".format(lang, rating_def))\n",
    "        predicted_results_path = f\"./train_test_data_models/{lang}/{rating_def}/predicted_results/predicted_scores.txt\"\n",
    "        test_file_path = f\"./train_test_data_models/{lang}/{rating_def}/test.txt\"\n",
    "        print(f\"Opening {predicted_results_path} and {test_file_path} - reading input ............\")\n",
    "        with open(predicted_results_path) as f:\n",
    "            lines = f.readlines()\n",
    "            predicted_scores = [float(score.replace('\\n','')) for score in lines]\n",
    "        user_mappings = []\n",
    "        scores = []\n",
    "        with open(test_file_path) as f:\n",
    "            for l in f:\n",
    "                user_mappings.append(int(l.split(':')[1]))\n",
    "                scores.append(int(l[0]))\n",
    "        dataframe_dict = {\n",
    "            \"user_mapping\": user_mappings,\n",
    "            \"score\": scores,\n",
    "            \"predicted_score\": predicted_scores\n",
    "        }\n",
    "        df = pd.DataFrame(dataframe_dict)\n",
    "        print(f\"Created test dataframe for {lang}-{rating_def}\")\n",
    "\n",
    "        print(f\"Separating data into groups {lang}-{rating_def} .....\")\n",
    "        agg_df = df[['user_mapping', 'score']].groupby(['user_mapping']).agg(['sum', 'count'])\n",
    "        agg_df = agg_df[(agg_df[\"score\"][\"sum\"] >= min_pos_labels) \\\n",
    "                         & (agg_df[\"score\"][\"count\"] >= min_total_user_events) \\\n",
    "                       & (agg_df[\"score\"][\"sum\"] != agg_df[\"score\"][\"count\"])]\n",
    "        selected_user_mappings = agg_df.sample(n = num_users_to_consider, replace=False).index.values\n",
    "\n",
    "        df = df[df.user_mapping.isin(selected_user_mappings)]\n",
    "        df = df.sort_values(\"user_mapping\")\n",
    "        all_user_mapping = df.user_mapping.values\n",
    "        scores = df.score.values\n",
    "        predicted_scores = df.predicted_score.values\n",
    "        ukeys, index = np.unique(all_user_mapping, True)\n",
    "        user_level_true_vals = np.split(scores, index[1:])\n",
    "        user_level_predicted_vals = np.split(predicted_scores, index[1:])\n",
    "        input_vals = list(zip(user_level_true_vals, user_level_predicted_vals))\n",
    "        print(f\"Input separated into groups for {lang}-{rating_def}\")\n",
    "        print(f\"Computing scores for {lang}-{rating_def}\")\n",
    "    #     with Pool(processes = 24) as sub_pool:\n",
    "    #         res = sub_pool.starmap(calculate_metric_scores, input_vals)\n",
    "        res = []\n",
    "        for true_vals, predicted_vals in tqdm(zip(user_level_true_vals, user_level_predicted_vals)):\n",
    "#             print(true_vals, predicted_vals)\n",
    "            temp_res = calculate_user_level_metric_scores(true_vals, predicted_vals)\n",
    "            res.append(temp_res)\n",
    "\n",
    "        means = np.array(res).mean(axis = 0)\n",
    "\n",
    "        results_dict = {\n",
    "            \"Rating Definition\": rating_key,\n",
    "            \"Language\": lang,\n",
    "            \"NDCG Score - User Level\": means[0],\n",
    "            \"AUC score - User Level\": means[1],\n",
    "            \"MAPK score - User Level\": means[2]\n",
    "            }\n",
    "        print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "saving-theta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for Hindi-is_vp_succ2\n",
      "Getting results for Hindi-is_vp_succ2\n",
      "Opening ./train_test_data_models/Hindi/is_vp_succ2/predicted_results/predicted_scores.txt and ./train_test_data_models/Hindi/is_vp_succ2/test.txt - reading input ............\n",
      "Calculating overall AUC scores - Hindi-is_vp_succ2\n",
      "Overall AUC scores computed - Hindi-is_vp_succ2\n",
      "Created test dataframe for Hindi-is_vp_succ2\n",
      "Separating data into groups Hindi-is_vp_succ2 .....\n",
      "Input separated into groups for Hindi-is_vp_succ2\n",
      "Computing scores for Hindi-is_vp_succ2\n",
      "Completed computing results for Hindi is_vp_succ2\n",
      "{'Rating Definition': 'is_vp_succ2', 'Language': 'Hindi', 'AUC score - Overall': 0.8094117656071651, 'NDCG@5 Score - User Level': 0.6335483608648548, 'NDCG@10 Score - User Level': 0.5937726673437211, 'AUC score - User Level': 0.7559612853287495, 'MAPK@5 score - User Level': 0.5233338333333528, 'MAPK@10 score - User Level': 0.4437434563492078}\n",
      "Getting results for Hindi-is_vp_skip\n",
      "Getting results for Hindi-is_vp_skip\n",
      "Opening ./train_test_data_models/Hindi/is_vp_skip/predicted_results/predicted_scores.txt and ./train_test_data_models/Hindi/is_vp_skip/test.txt - reading input ............\n",
      "Calculating overall AUC scores - Hindi-is_vp_skip\n",
      "Overall AUC scores computed - Hindi-is_vp_skip\n",
      "Created test dataframe for Hindi-is_vp_skip\n",
      "Separating data into groups Hindi-is_vp_skip .....\n",
      "Input separated into groups for Hindi-is_vp_skip\n",
      "Computing scores for Hindi-is_vp_skip\n",
      "Completed computing results for Hindi is_vp_skip\n",
      "{'Rating Definition': 'is_vp_skip', 'Language': 'Hindi', 'AUC score - Overall': 0.7397915548064928, 'NDCG@5 Score - User Level': 0.7830978439765075, 'NDCG@10 Score - User Level': 0.7154560320564455, 'AUC score - User Level': 0.6828310436971734, 'MAPK@5 score - User Level': 0.7093703333333223, 'MAPK@10 score - User Level': 0.5912715972222189}\n"
     ]
    }
   ],
   "source": [
    "for lang in LANGS:\n",
    "    for rating_key, rating_def in rating_def_dict.items():\n",
    "        print(\"Getting results for {}-{}\".format(lang, rating_def))\n",
    "        predicted_results_path = f\"./train_test_data_models/{lang}/{rating_def}/predicted_results/predicted_scores.txt\"\n",
    "#         trained_model_path = f\"./train_test_data_models/{lang}/{rating_def}/out/model.out\"\n",
    "#         predicted_output_folder_path = f\"./train_test_data_models/{lang}/{rating_def}/predicted_results\"\n",
    "#         predicted_output_file_name = \"predicted_scores.txt\"\n",
    "        test_file_path = f\"./train_test_data_models/{lang}/{rating_def}/test.txt\"\n",
    "#         predicted_results_path = f\"./train_test_data_models/{lang}/{rating_def}/predicted_results/predicted_scores.txt\"\n",
    "#         predict_scores(test_file_path, trained_model_path, predicted_output_folder_path,\n",
    "#                       lang, rating_def, predicted_output_file_name=predicted_output_file_name)\n",
    "#         predicted_results_path = os.path.join(predicted_output_folder_path, predicted_output_file_name)\n",
    "        \n",
    "        test_file_path = f\"./train_test_data_models/{lang}/{rating_def}/test.txt\"\n",
    "        print(\"Getting results for {}-{}\".format(lang, rating_def))\n",
    "        print(f\"Opening {predicted_results_path} and {test_file_path} - reading input ............\")\n",
    "        with open(predicted_results_path) as f:\n",
    "            lines = f.readlines()\n",
    "            predicted_scores = [float(score.replace('\\n','')) for score in lines]\n",
    "        user_mappings = []\n",
    "        scores = []\n",
    "        with open(test_file_path) as f:\n",
    "            for l in f:\n",
    "                user_mappings.append(int(l.split(':')[1]))\n",
    "                scores.append(int(l[0]))\n",
    "        dataframe_dict = {\n",
    "            \"user_mapping\": user_mappings,\n",
    "            \"score\": scores,\n",
    "            \"predicted_score\": predicted_scores\n",
    "        }\n",
    "        print(f\"Calculating overall AUC scores - {lang}-{rating_def}\")\n",
    "        auc_overall = roc_auc_score(scores, predicted_scores)\n",
    "        print(f\"Overall AUC scores computed - {lang}-{rating_def}\")\n",
    "\n",
    "        df = pd.DataFrame(dataframe_dict)\n",
    "        print(f\"Created test dataframe for {lang}-{rating_def}\")\n",
    "\n",
    "        print(f\"Separating data into groups {lang}-{rating_def} .....\")\n",
    "        agg_df = df[['user_mapping', 'score']].groupby(['user_mapping']).agg(['sum', 'count'])\n",
    "        agg_df = agg_df[(agg_df[\"score\"][\"sum\"] >= min_pos_labels) \\\n",
    "                         & (agg_df[\"score\"][\"count\"] >= min_total_user_events) \\\n",
    "                       & (agg_df[\"score\"][\"sum\"] != agg_df[\"score\"][\"count\"])]\n",
    "        selected_user_mappings = agg_df.sample(n = num_users_to_consider, replace=False).index.values\n",
    "\n",
    "        df = df[df.user_mapping.isin(selected_user_mappings)]\n",
    "        df = df.sort_values(\"user_mapping\")\n",
    "        all_user_mapping = df.user_mapping.values\n",
    "        scores = df.score.values\n",
    "        predicted_scores = df.predicted_score.values\n",
    "        ukeys, index = np.unique(all_user_mapping, True)\n",
    "        user_level_true_vals = np.split(scores, index[1:])\n",
    "        user_level_predicted_vals = np.split(predicted_scores, index[1:])\n",
    "        input_vals = list(zip(user_level_true_vals, user_level_predicted_vals))\n",
    "        print(f\"Input separated into groups for {lang}-{rating_def}\")\n",
    "        print(f\"Computing scores for {lang}-{rating_def}\")\n",
    "        with Pool(processes = 48) as sub_pool:\n",
    "            res = sub_pool.starmap(calculate_user_level_metric_scores, input_vals)\n",
    "#             res = []\n",
    "#             for true_vals, predicted_vals in tqdm(zip(user_level_true_vals, user_level_predicted_vals)):\n",
    "#         #             print(true_vals, predicted_vals)\n",
    "#                 temp_res = calculate_user_level_metric_scores(true_vals, predicted_vals)\n",
    "#                 res.append(temp_res)        \n",
    "        means = np.array(res).mean(axis = 0)\n",
    "\n",
    "        results_dict = {\n",
    "            \"Rating Definition\": rating_def,\n",
    "            \"Language\": lang,\n",
    "            \"AUC score - Overall\": auc_overall,\n",
    "            \"NDCG@5 Score - User Level\": means[0],\n",
    "            \"NDCG@10 Score - User Level\": means[1],\n",
    "            \"AUC score - User Level\": means[2],\n",
    "            \"MAPK@5 score - User Level\": means[3],\n",
    "            \"MAPK@10 score - User Level\": means[4]\n",
    "            }\n",
    "        print(\"Completed computing results for {} {}\".format(lang, rating_def))\n",
    "        print(results_dict)\n",
    "        df = pd.DataFrame([results_dict])\n",
    "        df.to_csv(\"./results/Hindi_rest_res_1.csv\", mode='a', \n",
    "                  index=False, header=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-crash",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-breed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "musical-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rating Definition': 'is_vp_skip',\n",
       " 'Language': 'Malayalam',\n",
       " 'AUC score - Overall': 0.7403779265112256,\n",
       " 'NDCG@5 Score - User Level': 0.7511589330745353,\n",
       " 'NDCG@10 Score - User Level': 0.714626302675468,\n",
       " 'AUC score - User Level': 0.6773018945198868,\n",
       " 'MAPK@5 score - User Level': 0.6617723333333213,\n",
       " 'MAPK@10 score - User Level': 0.5869704742063461}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-suspension",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"./aggregated_results/other_metrics_1.csv\", mode='a', \n",
    "          index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metric-ranch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495644647, 769884558)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_scores), len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "rough-entry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.1 ms, sys: 19.9 ms, total: 67 ms\n",
      "Wall time: 65.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_mapping_df = df[df.user_mapping == user_mapping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "massive-broad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2447441"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.predicted_score.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "thermal-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df.user_mapping.isin(selected_user_mappings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "interested-percentage",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_df = df[df.userId.isin(selected_userIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ordered-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2447441, 2447441, 62711999)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(\"user_mapping\")\n",
    "all_user_mapping = df.user_mapping.values\n",
    "scores = df.score.values\n",
    "precicted_scores = df.predicted_score.values\n",
    "len(all_user_mapping), len(scores), len(predicted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "twelve-quick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_mapping</th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7782684</th>\n",
       "      <td>68939</td>\n",
       "      <td>0</td>\n",
       "      <td>0.788298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032797</th>\n",
       "      <td>68939</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7017182</th>\n",
       "      <td>68939</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12573382</th>\n",
       "      <td>68939</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53359825</th>\n",
       "      <td>68939</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_mapping  score  predicted_score\n",
       "7782684          68939      0         0.788298\n",
       "7032797          68939      0         0.687772\n",
       "7017182          68939      1         0.500768\n",
       "12573382         68939      0         0.313040\n",
       "53359825         68939      0         0.577004"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "agreed-lending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9857235382</th>\n",
       "      <td>119103269175624</td>\n",
       "      <td>199314537408</td>\n",
       "      <td>77330</td>\n",
       "      <td>25836.966834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365384382</th>\n",
       "      <td>116716063066117</td>\n",
       "      <td>195051641932</td>\n",
       "      <td>72874</td>\n",
       "      <td>25429.166583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329535382</th>\n",
       "      <td>106995824611773</td>\n",
       "      <td>178190688536</td>\n",
       "      <td>70690</td>\n",
       "      <td>23113.308994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062058282</th>\n",
       "      <td>98212164199390</td>\n",
       "      <td>163874211312</td>\n",
       "      <td>68897</td>\n",
       "      <td>21243.150008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372802382</th>\n",
       "      <td>90735147065879</td>\n",
       "      <td>152006896006</td>\n",
       "      <td>68039</td>\n",
       "      <td>19701.435099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     userId         tagId  score  predicted_score\n",
       "postId                                                           \n",
       "9857235382  119103269175624  199314537408  77330     25836.966834\n",
       "3365384382  116716063066117  195051641932  72874     25429.166583\n",
       "9329535382  106995824611773  178190688536  70690     23113.308994\n",
       "9062058282   98212164199390  163874211312  68897     21243.150008\n",
       "1372802382   90735147065879  152006896006  68039     19701.435099"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['postId']).sum().sort_values(by=['score'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "considerable-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = df[['userId', 'score']].groupby(['userId']).agg(['sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "improved-anger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55914986, 5)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beautiful-madness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('score',   'sum'),\n",
       "            ('score', 'count')],\n",
       "           )"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "revolutionary-sense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     53871,      55059,      55062,      55564,      56773,\n",
       "                 57106,      57358,      57549,      58644,      58785,\n",
       "            ...\n",
       "            2777448214, 2777458053, 2777461328, 2777461595, 2777473212,\n",
       "            2777478170, 2777479686, 2777479756, 2777481430, 2777483046],\n",
       "           dtype='int64', name='userId', length=1125986)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "working-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  3, 22, ...,  1,  3,  1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df[('score', 'sum')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "manufactured-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = agg_df[(agg_df[\"score\"][\"sum\"] >= min_pos_labels) & (agg_df[\"score\"][\"count\"] >= min_total_user_events)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "atomic-median",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'userId'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'userId'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2d12a67e8d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"userId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3021\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3024\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m         \u001b[0;31m# self.columns is a MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3074\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3075\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3076\u001b[0m             \u001b[0mnew_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method)\u001b[0m\n\u001b[1;32m   2874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2876\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2877\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_maybe_to_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   3156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3158\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc_single_level_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexsort_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2807\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlevel_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'userId'"
     ]
    }
   ],
   "source": [
    "temp_df[\"userId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "absolute-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = agg_df.sample(n = 20000, replace=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "hollow-laundry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 176951320, 2618125270, 2580975920,  323434670,  352372614])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "junior-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>postId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1114791014</td>\n",
       "      <td>7031720382</td>\n",
       "      <td>102871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453980094</td>\n",
       "      <td>5351672082</td>\n",
       "      <td>830883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2738524875</td>\n",
       "      <td>5325077382</td>\n",
       "      <td>3464496</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53693143</td>\n",
       "      <td>9836841382</td>\n",
       "      <td>1381366</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>618968903</td>\n",
       "      <td>5837607382</td>\n",
       "      <td>4474183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId      postId    tagId  score  predicted_score\n",
       "0  1114791014  7031720382   102871      0         0.031885\n",
       "1   453980094  5351672082   830883      0         0.023767\n",
       "2  2738524875  5325077382  3464496      0         0.144696\n",
       "3    53693143  9836841382  1381366      1         0.044900\n",
       "4   618968903  5837607382  4474183      0         0.034953"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "warming-throat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>postId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46573</th>\n",
       "      <td>2618125270</td>\n",
       "      <td>7919181382</td>\n",
       "      <td>1381366</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86354</th>\n",
       "      <td>2618125270</td>\n",
       "      <td>7967645182</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88520</th>\n",
       "      <td>352372614</td>\n",
       "      <td>7212202382</td>\n",
       "      <td>1272240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126024</th>\n",
       "      <td>2618125270</td>\n",
       "      <td>7981172182</td>\n",
       "      <td>9777582</td>\n",
       "      <td>0</td>\n",
       "      <td>0.143801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207918</th>\n",
       "      <td>352372614</td>\n",
       "      <td>1458832382</td>\n",
       "      <td>1381366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55210329</th>\n",
       "      <td>352372614</td>\n",
       "      <td>1491271182</td>\n",
       "      <td>8291806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55339373</th>\n",
       "      <td>176951320</td>\n",
       "      <td>7423722282</td>\n",
       "      <td>711045</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55607095</th>\n",
       "      <td>352372614</td>\n",
       "      <td>7217636382</td>\n",
       "      <td>1272240</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55723968</th>\n",
       "      <td>2618125270</td>\n",
       "      <td>3287529082</td>\n",
       "      <td>102871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55885142</th>\n",
       "      <td>352372614</td>\n",
       "      <td>1726491382</td>\n",
       "      <td>894564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId      postId    tagId  score  predicted_score\n",
       "46573     2618125270  7919181382  1381366      1         0.278692\n",
       "86354     2618125270  7967645182       74      0         0.128524\n",
       "88520      352372614  7212202382  1272240      0         0.023171\n",
       "126024    2618125270  7981172182  9777582      0         0.143801\n",
       "207918     352372614  1458832382  1381366      0         0.022506\n",
       "...              ...         ...      ...    ...              ...\n",
       "55210329   352372614  1491271182  8291806      0         0.080947\n",
       "55339373   176951320  7423722282   711045      0         0.826163\n",
       "55607095   352372614  7217636382  1272240      1         0.078268\n",
       "55723968  2618125270  3287529082   102871      0         0.182957\n",
       "55885142   352372614  1726491382   894564      0         0.059187\n",
       "\n",
       "[508 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.userId.isin(t.index.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "white-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[df.userId == 176951320].sort_values(by = ['predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "statewide-spread",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only ('multilabel-indicator', 'continuous-multioutput', 'multiclass-multioutput') formats are supported. Got binary instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-fef801da2745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mndcg_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mndcg_score\u001b[0;34m(y_true, y_score, k, sample_weight, ignore_ties)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0m_check_dcg_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m     \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ndcg_sample_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_ties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_ties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_check_dcg_target_type\u001b[0;34m(y_true)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                      \"multiclass-multioutput\")\n\u001b[1;32m   1306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_fmt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1308\u001b[0m             \"Only {} formats are supported. Got {} instead\".format(\n\u001b[1;32m   1309\u001b[0m                 supported_fmt, y_type))\n",
      "\u001b[0;31mValueError\u001b[0m: Only ('multilabel-indicator', 'continuous-multioutput', 'multiclass-multioutput') formats are supported. Got binary instead"
     ]
    }
   ],
   "source": [
    "ndcg_score(temp.score.values, temp.predicted_score.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "analyzed-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vals = np.asarray([temp.score.values])\n",
    "pr_vals = np.asarray([temp.predicted_score.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "meaningful-circumstances",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7520911855422138"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_score(tr_vals,pr_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "small-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_score(np.array([[3,1,1,0,0]]), np.array([[2,1,0.2,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "blank-queensland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(tr_vals[0], pr_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "joined-hughes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "breeding-ethnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33999999999999997"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_recommendations = np.where(tr_vals[0] == 1)[0]\n",
    "ordered_recommendations = np.argsort(-pr_vals[0])\n",
    "apk(relevant_recommendations, ordered_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "derived-innocent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  8, 12])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "straight-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1,  0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "pretty-wrestling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "distinguished-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./train_test_data_models/Malayalam/is_vp_succ2/test_later.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "persistent-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path) as f:\n",
    "    lines = f.readlines()\n",
    "    labels = [int(l.replace('\\n', '')[0]) for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "reasonable-baseline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "addressed-change",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0318848, 0.0237671, 0.144696, 0.0449003, 0.0349526]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "improving-subsection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400228558390365"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(labels, predicted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "quantitative-retention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0:347890:1 1:1475:1 \\n'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "electronic-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 0', '347890', '1 1', '1475', '1 \\n']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0].split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "wicked-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    \"c1\": [1,2,2,3,2,2,4,5,5,9],\n",
    "    \"c2\": [1,0,0,0,1,1,1,0,1,0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "derived-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "handy-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2\n",
       "0   1   1\n",
       "1   2   0\n",
       "2   2   0\n",
       "3   3   0\n",
       "4   2   1\n",
       "5   2   1\n",
       "6   4   1"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.groupby(\"c1\").filter(lambda x: x.c1.max() < 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "practical-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_group(x, selected_user_mappings):\n",
    "    if x.user_mapping in selected_user_mappings:\n",
    "        true_vals = x.score.values\n",
    "        predicted_vals = x.predicted_score.values\n",
    "        print(true_vals, predicted_vals)\n",
    "        user_ndcg_score = ndcg_score(true_vals[np.newaxis, :], predicted_vals[np.newaxis, :])\n",
    "        relevant_recommendations = np.where(true_vals == 1)[0]\n",
    "        ordered_recommendations = np.argsort(-predicted_vals)\n",
    "        user_apk_score = apk(relevant_recommendations, ordered_recommendations)\n",
    "        return (user_ndcg_score, user_auc_score, user_apk_score)\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incoming-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_1(p1, p2):\n",
    "    p1 = p1[0]\n",
    "    p2 = p2[0]\n",
    "    return [p1+p1*p2, p1-p1*p2]\n",
    "params = [([1],[2]),([2],[3]),[[3],[4]],[[4],[5]]]\n",
    "with Pool(processes=10) as pool:\n",
    "    res = pool.starmap(mp_1, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complete-anderson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, -1], [8, -4], [15, -9], [24, -16]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hispanic-asbestos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, -1], [8, -4], [15, -9], [24, -16]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "provincial-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [np.arange(3), np.arange(3)+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regulation-match",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2]), array([2, 3, 4])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "finnish-watershed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brilliant-airline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "concerned-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    \"c1\": [1,2,2,3,2,2,4,5,5,9],\n",
    "    \"c2\": [1,0,0,0,1,1,1,0,1,0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decent-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "universal-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1 = df.sort_values('c1').c2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "asian-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.sort_values('c1').c1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interpreted-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = np.unique(temp, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "immediate-intent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1]),\n",
       " array([0, 0, 1, 1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0, 1]),\n",
       " array([0])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.split(temp_1, index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "injured-blond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2\n",
       "0   1   1\n",
       "1   2   0\n",
       "2   2   0\n",
       "4   2   1\n",
       "5   2   1\n",
       "3   3   0\n",
       "6   4   1\n",
       "7   5   0\n",
       "8   5   1\n",
       "9   9   0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "neither-mount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469024295259745"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "from math import log\n",
    "# we have groud-truth relevance of some answers to a query:\n",
    "true_relevance = np.asarray([[1, 1, 0, 0, 1, 0]])\n",
    "# we predict some scores (relevance) for the answers\n",
    "scores = np.asarray([[.9, .85, .8, .7, .65, 0.15]])\n",
    "ndcg_score(true_relevance, scores)\n",
    "\n",
    "# scores = np.asarray([[.05, 1.1, 1., .5, .0]])\n",
    "# ndcg_score(true_relevance, scores)\n",
    "\n",
    "# we can set k to truncate the sum; only top k answers contribute.\n",
    "\n",
    "\n",
    "# the normalization takes k into account so a perfect answer\n",
    "# would still get 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acute-party",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7653606369886218"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_score(true_relevance, scores, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "presidential-youth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_relevance = np.asarray([[1, 1, 0, 0]])\n",
    "# we predict some scores (relevance) for the answers\n",
    "scores = np.asarray([[.9, .85, .8, .7]])\n",
    "ndcg_score(true_relevance, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "framed-authority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1309297535714573"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/log(2,2)+1/log(3,2)+1/log(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "express-darkness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6309297535714573"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/log(2,2)+1/log(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "controlling-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652582159624413"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.63/2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "naked-approach",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1bcefc3e94b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./train_test_data_models/Kannada/is_vp_succ2/user_post_ffm_mapping.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "temp_df = pd.read_csv(\"./train_test_data_models/Kannada/is_vp_succ2/user_post_ffm_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "announced-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "damaged-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"col1\",\"col2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adult-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./results/temp_res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ancient-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{\"col1\": 1, \"col2\":2}]).to_csv(\"./results/temp_res.csv\", index=False, header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "instrumental-shadow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [col1, col2]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "animal-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {\n",
    "    \"col1\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "breeding-sheep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col1']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(temp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "likely-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pd.read_csv(\"./train_test_data_models/price/video/Hindi/is_vp_succ2/user_post_ffm_mapping.csv\",\n",
    "                        delimiter=\"\\t\", index_col=\"feature_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "north-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_buckets = pd.read_csv(\"./train_test_data_models/price/video/Hindi/is_vp_succ2/user_buckets.csv\",\n",
    "                        delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "canadian-education",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapping</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_post_1000001092</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_post_1000017582</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_post_1000035292</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_post_1000063692</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_post_1000143292</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mapping\n",
       "feature_name              \n",
       "1_post_1000001092        1\n",
       "1_post_1000017582        2\n",
       "1_post_1000035292        3\n",
       "1_post_1000063692        4\n",
       "1_post_1000143292        5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "saving-necessity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>user_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>617518841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1239023680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>335851653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>758602948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466911063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  user_bucket\n",
       "0   617518841            1\n",
       "1  1239023680            1\n",
       "2   335851653            1\n",
       "3   758602948            1\n",
       "4   466911063            1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_buckets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hearing-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_buckets[\"userId\"] = user_buckets.userId.apply(lambda x: \"2_user_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "swedish-creativity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>user_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_user_617518841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_user_1239023680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_user_335851653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_user_758602948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_user_466911063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId  user_bucket\n",
       "0   2_user_617518841            1\n",
       "1  2_user_1239023680            1\n",
       "2   2_user_335851653            1\n",
       "3   2_user_758602948            1\n",
       "4   2_user_466911063            1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_buckets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "arabic-research",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20848930"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_df.loc[\"2_user_617518841\"].mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "peaceful-station",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 617518841, 1239023680,  335851653,  758602948,  466911063,\\n             476648811, 1243857180, 2191549964, 1220246782, 1783813496,\\n            ...\\n              79850567,  436423780, 1121830546, 1606275329, 2003154809,\\n            1467283180,    8472216, 2249650404, 1796182349, 1137592414],\\n           dtype='int64', name='feature_name', length=23816606)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7736ebccd6cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_buckets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_mapping\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_buckets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1055\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([ 617518841, 1239023680,  335851653,  758602948,  466911063,\\n             476648811, 1243857180, 2191549964, 1220246782, 1783813496,\\n            ...\\n              79850567,  436423780, 1121830546, 1606275329, 2003154809,\\n            1467283180,    8472216, 2249650404, 1796182349, 1137592414],\\n           dtype='int64', name='feature_name', length=23816606)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "user_buckets[\"user_mapping\"] = mapping_df.loc[list(user_buckets.userId.values)].mapping.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_buckets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "moral-david",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20848930,  2146462, 15123015, 22143603])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_df.loc[['2_user_617518841',\n",
    " '2_user_1239023680',\n",
    " '2_user_335851653',\n",
    " '2_user_758602948']].mapping.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-premium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
