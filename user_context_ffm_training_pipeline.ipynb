{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "corrected-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery, storage\n",
    "from datetime import datetime, timedelta\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "from google.cloud.exceptions import NotFound\n",
    "from utils.download_from_GCP import download_table_to_local_as_one_file\n",
    "from utils.read_sql_as_string import readSqlFile\n",
    "from utils.simple_logging import get_standard_logger\n",
    "import ipynbname\n",
    "import xlearn as xl\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mature-christopher",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------ Fresh Run -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level set\n"
     ]
    }
   ],
   "source": [
    "nb_name = ipynbname.name()\n",
    "logger = get_standard_logger(nb_name, file_path=f\"logs/{nb_name}\", \n",
    "                             overwrite_file=True, stream=True)\n",
    "log_print = logger.info\n",
    "log_print(\"------------ Fresh Run -------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ideal-worth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohitrr/miniconda3/envs/py3.8/lib/python3.8/site-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project=\"sharechat-production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "modified-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGS = [\n",
    "    \"Hindi\",\n",
    "    # \"Tamil\",\n",
    "    # \"Telugu\",\n",
    "#     \"Kannada\",\n",
    "#     \"Punjabi\",\n",
    "#     \"Odia\",\n",
    "#     \"Bengali\",\n",
    "#     \"Marathi\",\n",
    "#     \"Malayalam\",\n",
    "#     \"Gujarati\",\n",
    "]\n",
    "# DAYS_OF_DATA_CONSIDERED = 7\n",
    "TRAINING_DAYS = 30\n",
    "TESTING_DAYS = 3\n",
    "rating_def_dict = {\n",
    "#         \"vplay\": \"is_vp_succ\",\n",
    "        \"like\": \"is_like\",\n",
    "#         \"share\": \"is_share\",\n",
    "#         \"fav\": \"is_fav\",\n",
    "#         \"vplay_skip\": \"is_vp_skip\",\n",
    "        \"vplay2\": \"is_vp_succ2\",\n",
    "    }\n",
    "BASE_BIG_QUERY_PATH = \"maximal-furnace-783.rohitrr\"\n",
    "RANDOM_SEED = 9745\n",
    "FFM_TEST_DATA_FILE_NAME = \"test.txt\"\n",
    "FFM_TRAIN_DATA_FILE_NAME = \"train.txt\"\n",
    "USER_CONTEXT = \"price\"\n",
    "DTYPE=\"video\"\n",
    "QUERY_BASE_FOLDER_PATH = f\"./queries/{DTYPE}/\"\n",
    "OVERWRITE_BASE_TABLE=True\n",
    "FULL_TEST_DATA=\"full_test_data.csv\"\n",
    "TEST_DATA_WITH_PREDICTIONS=\"test_with_predictions.csv\"\n",
    "PREDICTED_XLEARN_OUTPUT=\"predicted_scores.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cultural-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tables(delete_tables_path_list):\n",
    "    for delete_table_path in delete_tables_path_list:\n",
    "        client.delete_table(delete_table_path)\n",
    "\n",
    "    log_print(\"All tables deleted\")\n",
    "    \n",
    "def predict_scores(test_file_path, test_model_path, predicted_output_folder_path,\n",
    "                   predicted_output_file_name = \"predicted_output.txt\"):\n",
    "    pathlib.Path(predicted_output_folder_path).mkdir(parents = True, exist_ok = True)\n",
    "    predicted_output_file_path = os.path.join(predicted_output_folder_path,\n",
    "                                             predicted_output_file_name)\n",
    "    print(f\"Predicting labels for test file - {test_file_path}\")\n",
    "    ffm_model = xl.create_ffm() \n",
    "    ffm_model.setTest(test_file_path)\n",
    "    ffm_model.setSigmoid()\n",
    "    ffm_model.predict(test_model_path, predicted_output_file_path)\n",
    "    print(f\"Predicted labels stored in {predicted_output_file_path}\")\n",
    "\n",
    "def create_tests_with_predicted_results_file(full_test_data_path, prediction_file_path,\n",
    "                                            test_data_with_predictions_dir_path, \n",
    "                                            test_data_with_predictions_file_name):\n",
    "    print(f\"Converting {full_test_data_path} to {TEST_DATA_WITH_PREDICTIONS}\")\n",
    "    pathlib.Path(test_data_with_predictions_dir_path).mkdir(parents = True, exist_ok = True)\n",
    "    test_data_with_predictions_file_path = os.path.join(test_data_with_predictions_dir_path, \n",
    "                                                        test_data_with_predictions_file_name)\n",
    "    f_out = open(test_data_with_predictions_file_path, 'w')\n",
    "    f_predicted_scores_in = open(prediction_file_path)\n",
    "    f_test_file_in = open(full_test_data_path)\n",
    "\n",
    "    header = next(f_test_file_in)\n",
    "    f_out.write(header.strip('\\n')+\",predicted_score\"+'\\n')\n",
    "    for test_data, predicted_score in zip(f_test_file_in, f_predicted_scores_in):\n",
    "        f_out.write(test_data.strip('\\n')+','+predicted_score.strip('\\n')+'\\n')\n",
    "    f_out.close()\n",
    "    f_test_file_in.close()\n",
    "    f_predicted_scores_in.close()\n",
    "    print(f\"Removing - {full_test_data_path}\")\n",
    "    os.remove(full_test_data_path)\n",
    "    print(f\"{full_test_data_path} to {test_data_with_predictions_file_path} completed\")\n",
    "    \n",
    "# def create_tests_with_predicted_results_file(full_test_data_path, prediction_file_path,\n",
    "#                                             test_data_with_predictions_dir_path, \n",
    "#                                             test_data_with_predictions_file_name):\n",
    "#         print(f\"Converting {full_test_data_path} to {TEST_DATA_WITH_PREDICTIONS}\")\n",
    "#         full_test_df = pd.read_csv(full_test_data_path)\n",
    "#         with open(prediction_file_path) as f:\n",
    "#             full_test_df[\"predicted_score\"] = f.read().splitlines()#[float(score) for score in f.read().splitlines()]\n",
    "#         full_test_df.to_csv(os.path.join(test_data_with_predictions_dir_path, \n",
    "#                                          test_data_with_predictions_file_name), \n",
    "#                             index=False)\n",
    "#         print(f\"Removing - {full_test_data_path}\")\n",
    "#         os.remove(full_test_data_path)\n",
    "#         print(f\"{full_test_data_path} to {os.path.join(test_data_with_predictions_dir_path, \n",
    "#                                          test_data_with_predictions_file_name)} completed\")\n",
    "\n",
    "def construct_base_table(lang, common_posts_end_time, \n",
    "                         common_posts_days, end_time, days,\n",
    "                         overwrite_base_table = False, \n",
    "                         mode = \"train\"):\n",
    "    \n",
    "    temp_q0_table_path = BASE_BIG_QUERY_PATH+'.'+\\\n",
    "    f'{DTYPE}_{mode}_temp_q0_table_{lang}_{common_end_time.date()}_{TRAINING_DAYS}'\n",
    "    \n",
    "    if(not overwrite_base_table):\n",
    "        try:\n",
    "            client.get_table(temp_q0_table_path)\n",
    "            log_print(f\"Table-{temp_q0_table_path} already exists, not overwriting\")\n",
    "            return temp_q0_table_path\n",
    "        except NotFound:\n",
    "            log_print(f\"Table-{temp_q0_table_path} not already present - going ahead creating it\")\n",
    "            \n",
    "    log_print(f\"Running query 0 for {lang} .....\")\n",
    "    job_config = bigquery.QueryJobConfig(destination= temp_q0_table_path,\n",
    "                                         write_disposition = \"WRITE_TRUNCATE\"\n",
    "                                         )\n",
    "    sql = readSqlFile(f\"{QUERY_BASE_FOLDER_PATH}/query0.sql\", lang = lang,\n",
    "                      common_posts_end_time = common_posts_end_time,\n",
    "                      common_posts_days = common_posts_days,\n",
    "                      end_time=end_time, days = days)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "    query_job.result()\n",
    "    log_print(f\"Query 0 results loaded to the table {temp_q0_table_path}\")\n",
    "    return temp_q0_table_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "entitled-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_prepare_train_data_with_base_table(lang, rating_def, user_context, base_q0_table_path,\n",
    "                                             save_path):\n",
    "    delete_tables = []\n",
    "    # Run Q1 query\n",
    "    temp_q0_table_path = base_q0_table_path\n",
    "    temp_q1_table_path = BASE_BIG_QUERY_PATH+'.'+f'{USER_CONTEXT}_{DTYPE}_train_temp_q1_table_{lang}_{rating_def}'\n",
    "    job_config = bigquery.QueryJobConfig(destination= temp_q1_table_path,\n",
    "                                         write_disposition = \"WRITE_TRUNCATE\"\n",
    "                                         )\n",
    "    sql = readSqlFile(f\"{QUERY_BASE_FOLDER_PATH}/{user_context}/query1.sql\", lang = lang, \n",
    "                      rating_def = rating_def,\n",
    "                     q0_table = temp_q0_table_path)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "    query_job.result()\n",
    "    log_print(f\"Query 1 results loaded to the table {temp_q1_table_path}\")\n",
    "    train_table_with_valid_user_post_ids = temp_q1_table_path\n",
    "    delete_tables.append(temp_q1_table_path)\n",
    "\n",
    "    # Run Q2 query\n",
    "    table_with_mapping = BASE_BIG_QUERY_PATH+'.'+f'{USER_CONTEXT}_{DTYPE}_train_temp_q2_table_{lang}_{rating_def}'\n",
    "    job_config = bigquery.QueryJobConfig(destination= table_with_mapping, \n",
    "                                         write_disposition = \"WRITE_TRUNCATE\")\n",
    "    sql = readSqlFile(f\"{QUERY_BASE_FOLDER_PATH}/{user_context}/query2.sql\", lang = lang, \n",
    "                      rating_def = rating_def,\n",
    "                     q1_table = temp_q1_table_path)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "    query_job.result()\n",
    "    log_print(f\"Query 2 results loaded to the table {table_with_mapping}\")\n",
    "    download_table_to_local_as_one_file(table_with_mapping, save_path, \n",
    "                                out_file_name = f\"user_post_ffm_mapping.csv\")\n",
    "    delete_tables.append(table_with_mapping)\n",
    "\n",
    "    # Run Q3 query\n",
    "    temp_q3_table_path = BASE_BIG_QUERY_PATH+'.'+f'{USER_CONTEXT}_{DTYPE}_train_temp_q3_table_{lang}_{rating_def}'\n",
    "    job_config = bigquery.QueryJobConfig(destination= temp_q3_table_path,\n",
    "                                         write_disposition = \"WRITE_TRUNCATE\"\n",
    "                                         )\n",
    "    sql = readSqlFile(f\"{QUERY_BASE_FOLDER_PATH}/{user_context}/query3.sql\", lang = lang, \n",
    "                      rating_def = rating_def,\n",
    "                      q1_table = temp_q1_table_path,\n",
    "                     q2_table = table_with_mapping)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "    query_job.result()\n",
    "    log_print(f\"Query 3 results loaded to the table {temp_q3_table_path}\")\n",
    "    delete_tables.append(temp_q3_table_path)\n",
    "\n",
    "#     Save results to local storage\n",
    "    download_table_to_local_as_one_file(temp_q3_table_path, save_path, with_header=False,\n",
    "                                        out_file_name = f\"{FFM_TRAIN_DATA_FILE_NAME}\")\n",
    "    return delete_tables, train_table_with_valid_user_post_ids, table_with_mapping\n",
    "\n",
    "def collect_and_prepare_test_data_with_base_table(lang, rating_def, user_context, base_q0_table_path, \n",
    "                                             table_with_valid_user_post_ids,\n",
    "                                            table_with_mapping,\n",
    "                                             save_path):\n",
    "    delete_tables = []\n",
    "    # Run Q1 query\n",
    "    temp_q0_table_path = base_q0_table_path\n",
    "    temp_q1_table_path = BASE_BIG_QUERY_PATH+'.'+ \\\n",
    "    f'{USER_CONTEXT}_{DTYPE}_test_temp_q1_table_{lang}_{rating_def}'\n",
    "    job_config = bigquery.QueryJobConfig(destination= temp_q1_table_path,\n",
    "                                         write_disposition = \"WRITE_TRUNCATE\"\n",
    "                                         )\n",
    "    # Changed query from the train case\n",
    "    sql = readSqlFile(f\"{QUERY_BASE_FOLDER_PATH}/{user_context}/test_query1.sql\", lang = lang, \n",
    "                      rating_def = rating_def,\n",
    "                     q0_table = temp_q0_table_path,\n",
    "                     train_q1_table = table_with_valid_user_post_ids)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "    query_job.result()\n",
    "    log_print(f\"Query 1 results loaded to the table {temp_q1_table_path}\")\n",
    "    delete_tables.append(temp_q1_table_path)\n",
    "    \n",
    "    # Run Q3 query\n",
    "    temp_q3_table_path = BASE_BIG_QUERY_PATH+'.'+f'{USER_CONTEXT}_{DTYPE}_test_temp_q3_table_{lang}_{rating_def}'\n",
    "    job_config = bigquery.QueryJobConfig(destination= temp_q3_table_path,\n",
    "                                         write_disposition = \"WRITE_TRUNCATE\"\n",
    "                                         )\n",
    "    sql = readSqlFile(f\"{QUERY_BASE_FOLDER_PATH}/{user_context}/query3.sql\", lang = lang, \n",
    "                      rating_def = rating_def,\n",
    "                      q1_table = temp_q1_table_path,\n",
    "                     q2_table = table_with_mapping)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "    query_job.result()\n",
    "    log_print(f\"Query 3 results loaded to the table {temp_q3_table_path}\")\n",
    "    delete_tables.append(temp_q3_table_path)\n",
    "\n",
    "#     Save results to local storage\n",
    "    download_table_to_local_as_one_file(temp_q1_table_path, save_path, \n",
    "                                        out_file_name = f\"{FULL_TEST_DATA}\")\n",
    "    download_table_to_local_as_one_file(temp_q3_table_path, save_path, with_header=False,\n",
    "                                        out_file_name = f\"{FFM_TEST_DATA_FILE_NAME}\")\n",
    "    return delete_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ready-antarctica",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-30 00:00:00\n",
      "2021-04-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "common_end_time = datetime(2021, 4, 30) # the hours, minutes and seconds are taken to be 0\n",
    "test_end_time = common_end_time\n",
    "train_end_time = common_end_time - timedelta(TESTING_DAYS)\n",
    "log_print(test_end_time)\n",
    "log_print(train_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-curve",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running query 0 for Hindi .....\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    for lang in LANGS:\n",
    "        base_q0_train_table_path = construct_base_table(lang, train_end_time, TRAINING_DAYS, \n",
    "                                                        train_end_time, TRAINING_DAYS,\n",
    "                                                 overwrite_base_table=OVERWRITE_BASE_TABLE, mode=\"train\")\n",
    "\n",
    "        base_q0_test_table_path = construct_base_table(lang, train_end_time, TRAINING_DAYS, \n",
    "                                                 test_end_time, TESTING_DAYS,\n",
    "                                                 overwrite_base_table=OVERWRITE_BASE_TABLE, mode=\"test\")\n",
    "\n",
    "        for key, rating_def in rating_def_dict.items():\n",
    "            save_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}\"\n",
    "            train_delete_table_paths, table_with_valid_user_post_ids, train_table_with_mapping = \\\n",
    "            collect_and_prepare_train_data_with_base_table(lang, rating_def, USER_CONTEXT,\n",
    "                                     base_q0_train_table_path, save_path)\n",
    "\n",
    "            test_delete_table_paths = \\\n",
    "            collect_and_prepare_test_data_with_base_table(lang, rating_def, USER_CONTEXT,\n",
    "                                     base_q0_test_table_path,\n",
    "                                     table_with_valid_user_post_ids,\n",
    "                                     train_table_with_mapping,\n",
    "                                     save_path\n",
    "                                     )\n",
    "    #         Delete all created tables\n",
    "    #         delete_tables(\n",
    "    #             train_delete_table_paths+test_delete_table_paths\n",
    "    #         )\n",
    "    #         Train using xlearn binary\n",
    "            log_print(f\"Training started for label {rating_def} in {lang} .......\")\n",
    "            model_output_path = os.path.join(save_path, \"out\")\n",
    "            pathlib.Path(model_output_path).mkdir(parents = True, exist_ok = True)\n",
    "            cmd = f\"./xlearn_train {save_path}/{FFM_TRAIN_DATA_FILE_NAME} \\\n",
    "            -v {save_path}/{FFM_TEST_DATA_FILE_NAME} -x auc -s 2 -k 32 -m {model_output_path}/model.out \\\n",
    "            -t {model_output_path}/model.txt -b 0.001 --disk 2>&1 | tee \\\n",
    "            {model_output_path}/logs\"\n",
    "            os.system(cmd)\n",
    "            log_print(f\"Model trained and saved in {model_output_path}\")\n",
    "            predict_scores(os.path.join(save_path, FFM_TEST_DATA_FILE_NAME), \n",
    "                           os.path.join(save_path, \"out/model.out\"),\n",
    "                          save_path, PREDICTED_XLEARN_OUTPUT)\n",
    "            create_tests_with_predicted_results_file(os.path.join(save_path, FULL_TEST_DATA),\n",
    "                                                    os.path.join(save_path, PREDICTED_XLEARN_OUTPUT),\n",
    "                                                    save_path, TEST_DATA_WITH_PREDICTIONS)\n",
    "            \n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-accreditation",
   "metadata": {},
   "source": [
    "### Scrap code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22820c88-46b0-422f-83b5-0e25b26650fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading table - maximal-furnace-783.rohitrr.price_video_test_temp_q1_table_Hindi_is_like to gcs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohitrr/miniconda3/envs/py3.8/lib/python3.8/site-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/home/rohitrr/miniconda3/envs/py3.8/lib/python3.8/site-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported maximal-furnace-783:rohitrr.price_video_test_temp_q1_table_Hindi_is_like to gs://query_runner_results/price_video_test_temp_q1_table_Hindi_is_like_2021-07-07_08:35:07_35/*.csv\n",
      "Downloading from gcs_folder_name price_video_test_temp_q1_table_Hindi_is_like_2021-07-07_08:35:07_35 to local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohitrr/miniconda3/envs/py3.8/lib/python3.8/site-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents in gs://query_runner_results/price_video_test_temp_q1_table_Hindi_is_like_2021-07-07_08:35:07_35     transferred to ./train_test_data_models/price/video/Hindi/is_like/temp_download_folder\n",
      "Merging and saving files from ./train_test_data_models/price/video/Hindi/is_like/temp_download_folder to ./train_test_data_models/price/video/Hindi/is_like\n",
      "Saved file full_test_data.csv in ./train_test_data_models/price/video/Hindi/is_like\n",
      "Download complete - Hindi-is_like\n",
      "Converting ./train_test_data_models/price/video/Hindi/is_like/full_test_data.csv to test_with_predictions.csv\n",
      "Removing - ./train_test_data_models/price/video/Hindi/is_like/full_test_data.csv\n",
      "./train_test_data_models/price/video/Hindi/is_like/full_test_data.csv to ./train_test_data_models/price/video/Hindi/is_like/test_with_predictions.csv completed\n",
      "Downloading table - maximal-furnace-783.rohitrr.price_video_test_temp_q1_table_Hindi_is_vp_succ2 to gcs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohitrr/miniconda3/envs/py3.8/lib/python3.8/site-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/home/rohitrr/miniconda3/envs/py3.8/lib/python3.8/site-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported maximal-furnace-783:rohitrr.price_video_test_temp_q1_table_Hindi_is_vp_succ2 to gs://query_runner_results/price_video_test_temp_q1_table_Hindi_is_vp_succ2_2021-07-07_08:45:12_57/*.csv\n",
      "Downloading from gcs_folder_name price_video_test_temp_q1_table_Hindi_is_vp_succ2_2021-07-07_08:45:12_57 to local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohitrr/miniconda3/envs/py3.8/lib/python3.8/site-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents in gs://query_runner_results/price_video_test_temp_q1_table_Hindi_is_vp_succ2_2021-07-07_08:45:12_57     transferred to ./train_test_data_models/price/video/Hindi/is_vp_succ2/temp_download_folder\n",
      "Merging and saving files from ./train_test_data_models/price/video/Hindi/is_vp_succ2/temp_download_folder to ./train_test_data_models/price/video/Hindi/is_vp_succ2\n",
      "Saved file full_test_data.csv in ./train_test_data_models/price/video/Hindi/is_vp_succ2\n",
      "Download complete - Hindi-is_vp_succ2\n",
      "Converting ./train_test_data_models/price/video/Hindi/is_vp_succ2/full_test_data.csv to test_with_predictions.csv\n",
      "Removing - ./train_test_data_models/price/video/Hindi/is_vp_succ2/full_test_data.csv\n",
      "./train_test_data_models/price/video/Hindi/is_vp_succ2/full_test_data.csv to ./train_test_data_models/price/video/Hindi/is_vp_succ2/test_with_predictions.csv completed\n"
     ]
    }
   ],
   "source": [
    "for lang in LANGS:\n",
    "    for _, rating_def in rating_def_dict.items():\n",
    "        save_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}\"\n",
    "        temp_q1_table_path = BASE_BIG_QUERY_PATH+'.'+ \\\n",
    "        f'{USER_CONTEXT}_{DTYPE}_test_temp_q1_table_{lang}_{rating_def}'\n",
    "        download_table_to_local_as_one_file(temp_q1_table_path, save_path,\n",
    "                                            out_file_name = f\"{FULL_TEST_DATA}\")\n",
    "        print(f\"Download complete - {lang}-{rating_def}\")\n",
    "        create_tests_with_predicted_results_file(os.path.join(save_path, FULL_TEST_DATA),\n",
    "                                                os.path.join(save_path, \"predicted_results\", PREDICTED_XLEARN_OUTPUT),\n",
    "                                                save_path, TEST_DATA_WITH_PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2fd518c-9b0a-4fc1-9aac-b352e2167de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"./train_test_data_models/price/video/Punjabi/is_vp_succ2/test_with_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "836b95ab-80a8-4ed2-9e67-eefc89b19186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>postId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>priceBucket</th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119850069</td>\n",
       "      <td>3392642692</td>\n",
       "      <td>310200</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107004367</td>\n",
       "      <td>3075435692</td>\n",
       "      <td>289363</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.180698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2669776446</td>\n",
       "      <td>7549436692</td>\n",
       "      <td>310046</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89287725</td>\n",
       "      <td>1469438792</td>\n",
       "      <td>3369258</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2660022015</td>\n",
       "      <td>3983633792</td>\n",
       "      <td>97350</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId      postId    tagId  priceBucket  score  predicted_score\n",
       "0   119850069  3392642692   310200           -1      0         0.033096\n",
       "1   107004367  3075435692   289363           -1      1         0.180698\n",
       "2  2669776446  7549436692   310046           -1      0         0.612420\n",
       "3    89287725  1469438792  3369258           -1      0         0.421509\n",
       "4  2660022015  3983633792    97350           -1      0         0.187146"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cba204b-4b27-46e7-8937-2b685cf45bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ./train_test_data_models/price/video/Hindi/is_like/full_test_data.csv to test_with_predictions.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train_test_data_models/price/video/Hindi/is_like/full_test_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2420e9ea0dc3>\u001b[0m in \u001b[0;36mcreate_tests_with_predicted_results_file\u001b[0;34m(full_test_data_path, prediction_file_path, test_data_with_predictions_dir_path, test_data_with_predictions_file_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_with_predictions_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mf_predicted_scores_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mf_test_file_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_test_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_test_file_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_test_data_models/price/video/Hindi/is_like/full_test_data.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for lang in LANGS:\n",
    "    for _, rating_def in rating_def_dict.items():\n",
    "        save_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}\"\n",
    "        create_tests_with_predicted_results_file(os.path.join(save_path, FULL_TEST_DATA),\n",
    "                                                os.path.join(save_path, PREDICTED_XLEARN_OUTPUT),\n",
    "                                                save_path, TEST_DATA_WITH_PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bdfc39a-c834-4e99-a8e5-3887d83280d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tests_with_predicted_results_file(full_test_data_path, prediction_file_path,\n",
    "                                            test_data_with_predictions_dir_path, \n",
    "                                            test_data_with_predictions_file_name):\n",
    "    print(f\"Converting {full_test_data_path} to {TEST_DATA_WITH_PREDICTIONS}\")\n",
    "    pathlib.Path(test_data_with_predictions_dir_path).mkdir(parents = True, exist_ok = True)\n",
    "    test_data_with_predictions_file_path = os.path.join(test_data_with_predictions_dir_path, \n",
    "                                                        test_data_with_predictions_file_name)\n",
    "    f_out = open(test_data_with_predictions_file_path, 'w')\n",
    "    f_predicted_scores_in = open(prediction_file_path)\n",
    "    f_test_file_in = open(full_test_data_path)\n",
    "\n",
    "    header = next(f_test_file_in)\n",
    "    f_out.write(header+\",predicted_score\")\n",
    "    for test_data, predicted_score in zip(f_test_file_in, f_predicted_scores_in):\n",
    "        f_out.write(test_data+','+predicted_score)\n",
    "    f_out.close()\n",
    "    f_test_file_in.close()\n",
    "    f_predicted_scores_in.close()\n",
    "    print(f\"Removing - {full_test_data_path}\")\n",
    "    os.remove(full_test_data_path)\n",
    "    print(f\"{full_test_data_path} to {test_data_with_predictions_file_path} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cd715-8d7a-405e-bfa4-7a7eb46cd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in LANGS:\n",
    "    for _, rating_def in rating_def_dict.items():\n",
    "        save_path = f\"./train_test_data_models/{USER_CONTEXT}/{DTYPE}/{lang}/{rating_def}\"\n",
    "        print(f\"Converting {FULL_TEST_DATA} to {TEST_DATA_WITH_PREDICTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f68c0897-ae68-4f0a-9605-d79ae47b3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./train_test_data_models/price/video/Hindi/is_like/predicted_scores.txt\") as f:\n",
    "    temp = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3477a92-2ff2-4505-aa11-0cb2ab52300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "statutory-integration",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "sql = readSqlFile(\"./queries/video/query0.sql\", \n",
    "                  lang = \"Odia\", rating_def = rating_def, \n",
    "                  end_time=end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f4e011c-5269-497b-9904-4208e470098f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afsd'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"afsd\\n\".strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_def = \"is_vp_succ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sharp-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for label is_vp_succ in Bengali .......\n",
      "Model trained and saved in ./train_test_data_models/Bengali/is_like/out\n"
     ]
    }
   ],
   "source": [
    "log_print(f\"Training started for label {rating_def} in {lang} .......\")\n",
    "model_output_path = os.path.join(save_path, \"out\")\n",
    "pathlib.Path(model_output_path).mkdir(parents = True, exist_ok = True)\n",
    "cmd = f\"./xlearn_train {save_path}/{TRAIN_DATA_FILE_NAME} \\\n",
    "-v {save_path}/{TEST_DATA_FILE_NAME} -x auc -s 2 -k 32 -m {model_output_path}/model.out \\\n",
    "-t {model_output_path}/model.txt -b 0.001 --disk 2>&1 | tee \\\n",
    "{model_output_path}/logs\"\n",
    "os.system(cmd)\n",
    "log_print(f\"Model trained and saved in {model_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "promising-repair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train_test_data_models/Bengali/is_like/train.txt\n"
     ]
    }
   ],
   "source": [
    "log_print(f\"{save_path}/{TRAIN_DATA_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_table(temp_q1_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "engaging-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(f\"./train_test_data/{rating_def}/{lang}\").mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "removed-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT * FROM `{temp_q3_table_path}`\n",
    "\"\"\"\n",
    "data_df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "brief-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size = 0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "forty-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"./train_test_data/{rating_def}/{lang}\"\n",
    "pathlib.Path(save_path).mkdir(parents = True, exist_ok = True)\n",
    "test_df.to_csv(os.path.join(save_path, \"test.txt\"), sep=\"\\n\", header = False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "confident-cream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.44 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 64 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 517707\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 2\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 23.14 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 256.74 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.34 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.418973            0.410742            0.769566               24.66\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.400472            0.404218            0.779871               24.93\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.375957            0.403592            0.782683               23.41\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.334905            0.418434            0.769949               23.34\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.295719            0.439514            0.754984               24.52\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.267937            0.459180            0.743783               23.32\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 3, best AUC: 0.782683\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: out/model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.21 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save txt model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mTXT Model file: out/model.txt\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving txt model: 13.31 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mTotal time cost: 181.45 (sec)\n"
     ]
    }
   ],
   "source": [
    "! ./xlearn_train ./train_test_data/is_vp_succ2/Odia/train.txt -v ./train_test_data/is_vp_succ2/Odia/test.txt -x auc -s 2 -k 32 -m out/model.out -t out/model.txt -b 0.001 --disk 2>&1 | tee out/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "together-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"./xlearn_train {save_path}/train.txt \\\n",
    "-v {save_path}/test.txt -x auc -s 2 -k 32 -m {model_output_path}/model.out \\\n",
    "-t {model_output_path}/model.txt -b 0.001 --disk 2>&1 | tee \\\n",
    "{model_output_path}/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "binary-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path = os.path.join(save_path, \"out\")\n",
    "pathlib.Path(model_output_path).mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "august-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "passing-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./xlearn_train ./train_test_data/is_vp_succ2/Odia/train.txt -v ./train_test_data/is_vp_succ2/Odia/test.txt -x auc -s 2 -k 32 -m ./train_test_data/is_vp_succ2/Odia/out/model.out -t ./train_test_data/is_vp_succ2/Odia/out/model.txt -b 0.001 --disk 2>&1 | tee ./train_test_data/is_vp_succ2/Odia/out/logs'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "gorgeous-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"touch check_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "polished-irrigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maximal-furnace-783.rohitrr.train_temp_q0_table_Odia_is_vp_succ2',\n",
       " 'maximal-furnace-783.rohitrr.train_temp_q1_table_Odia_is_vp_succ2',\n",
       " 'maximal-furnace-783.rohitrr.train_temp_q2_table_Odia_is_vp_succ2',\n",
       " 'maximal-furnace-783.rohitrr.train_temp_q3_table_Odia_is_vp_succ2']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_delete_table_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "actual-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "configured-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 10\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "defensive-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./train_test_data_models/is_vp_succ2/Kannada/user_post_ffm_mapping.csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = \",\")\n",
    "    i = 0\n",
    "    for row in csv_reader:\n",
    "        rows.append(row)\n",
    "        i+=1\n",
    "        if(i > count):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "grave-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_post_1000004482', '1']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "intellectual-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./train_test_data_models/is_vp_succ2/Kannada/user_post_ffm_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "seven-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1_post_1000004482\\t1\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "growing-wheel",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "check",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ade9bbba3fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: check"
     ]
    }
   ],
   "source": [
    "raise Exception(\"check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "earlier-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./train_test_data_models/Bengali/is_vp_succ/test.txt\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "important-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21455608238342266\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for l in lines:\n",
    "    if(l[0] == \"1\"):\n",
    "        count+=1\n",
    "log_print(count/len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-street",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "corporate-energy",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'strftime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d4b5f89e9601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sql = readSqlFile(f\"{QUERY_FOLDER_PATH}/query0.sql\", lang = \"Hindi\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mcommon_posts_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"akahfk\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mcommon_posts_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"afkhd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   end_time=\"afljds\", days = \"ajkfdks\")\n",
      "\u001b[0;32m~/test/referrer_ffm_test/utils/read_sql_as_string.py\u001b[0m in \u001b[0;36mreadSqlFile\u001b[0;34m(file_path, lang, rating_def, q0_table, q1_table, q2_table, train_q1_table, end_time, days, common_posts_end_time, common_posts_days)\u001b[0m\n\u001b[1;32m      7\u001b[0m         sql_command = sql_command.format(\n\u001b[1;32m      8\u001b[0m             \u001b[0mcommon_posts_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_posts_end_time\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcommon_posts_end_time\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                     \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_posts_end_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mcommon_posts_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_posts_days\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'strftime'"
     ]
    }
   ],
   "source": [
    "sql = readSqlFile(f\"{QUERY_FOLDER_PATH}/query0.sql\", lang = \"Hindi\",\n",
    "                  common_posts_end_time = \"akahfk\",\n",
    "                  common_posts_days = \"afkhd\",\n",
    "                  end_time=\"afljds\", days = \"ajkfdks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recognized-calibration",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QUERY_FOLDER_PAT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1e4180e403ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34mf\"{QUERY_FOLDER_PAT}afsd\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'QUERY_FOLDER_PAT' is not defined"
     ]
    }
   ],
   "source": [
    "f\"{QUERY_FOLDER_PAT}afsd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "affiliated-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unsigned-brazilian",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find the current session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/ipynb_path/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(name, password)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-549186c9cc03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mipynb_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/ipynb_path/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(name, password)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_notebook_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/ipynb_path/core.py\u001b[0m in \u001b[0;36mcurrent_notebook_path\u001b[0;34m(password)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_notebook_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mclients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJupyterRestfulApi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_current_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'notebook_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.8/lib/python3.8/site-packages/ipynb_path/core.py\u001b[0m in \u001b[0;36mfind_current_session\u001b[0;34m(clients)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not find the current session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find the current session."
     ]
    }
   ],
   "source": [
    "ipynb_path.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "mental-robin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var nb = IPython.notebook;\n",
       "var kernel = IPython.notebook.kernel;\n",
       "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
       "kernel.execute(command);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "practical-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "nb_fname = ipynbname.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "elegant-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user_context_ffm_training_pipeline_small_languages'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "demanding-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import simple_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stainless-drain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level set\n"
     ]
    }
   ],
   "source": [
    "nb_name = ipynbname.name()\n",
    "logger = simple_logging.get_standard_logger(nb_name, file_path=f\"logs/{nb_name}\", overwrite_file=True, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "willing-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test - 1\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Test - 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "national-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_print  = logger.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "shaped-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "log_print(\"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "supposed-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_func(l):\n",
    "    try:\n",
    "        if(l == 1):\n",
    "            print(l, \" returning\")\n",
    "            return l+1\n",
    "    except Exception as e:\n",
    "        print(\"Exception\")\n",
    "        return l-1\n",
    "    print(\"After returning\")\n",
    "    return l+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "peripheral-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  returning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_func(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adapted-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accurate-costume",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c974bbcb2bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "b = a+d \n",
    "print(b+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "scientific-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d242200f085c9645a59da064fb13f57c599d035914427fde7d2ccde7ce4c1817"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
